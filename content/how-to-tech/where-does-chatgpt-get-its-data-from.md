---
title: Where does ChatGPT get its data from?
slug: where does ChatGPT get data from
postdate: March 28, 2023
description: The ChatGPT model, is trained on a large dataset of text data which
  comes from a variety of sources, such as books, articles, websites, and social
  media. The text data is carefully curated to ensure that it represents a
  diverse range of topics and styles of writing.
categorylabel: Tech Stuff
categories: '["How-to-tech"]'
image: /images/ilgmyzin-agfmimwypso-unsplash-1-.webp
weight: 111
categorylink: /categories/how-to-tech
type: posts
author: Mohammad Jamiu
draft: false
mathjax: false
Google_Ads: true
---

![chatgpt](/images/ilgmyzin-agfmimwypso-unsplash-1-.webp "chatgpt")

## Key Terminologies

### What is an AI?

**AI is a short form for Artificial Intelligence**. It refers to the development of computer systems that can perform tasks that normally require human intelligence, such as recognizing speech, understanding natural language, making decisions, and recognizing patterns in data.

AI systems are designed to learn and improve over time, using algorithms that can identify patterns in data and make predictions based on that data. Some AI systems can also adapt to new situations and make decisions based on their past experiences.

### What is Machine Learning?

**Machine learning** is a field of artificial intelligence (AI) that focuses on the development of computer algorithms that can learn from and make predictions on data. The goal of machine learning is to create models that can automatically learn patterns in data, and use these patterns to make accurate predictions or decisions without being explicitly programmed.

## Where does ChatGPT get its data from?

**ChatGPT** is a large language model developed by OpenAI, based on the GPT architecture. GPT stands for “Generative Pre-trained Transformer,” which is a type of neural network architecture used for natural language processing tasks, such as text generation, language translation, and question answering.

There have been several versions of the GPT architecture, each with increasing capacity and performance. The first version, GPT-1, was released by OpenAI in 2018, and had 117 million parameters. GPT-1 achieved state-of-the-art performance on numerous natural language processing benchmarks at the time, such as language modeling and text completion tasks.

The second version, GPT-2, was released in 2019, and was much larger than its predecessor (GPT-1), with 1.5 billion parameters. GPT-2 achieved impressive results on a wide range of natural language processing tasks, including generating realistic text, summarizing documents, and answering questions.

Other versions of the GPT architecture is GPT-3, GPT-3.5 and GPT-4 (the newest OpenAI model). GPT-3 has a staggering 175 billion parameters, while GPT-3.5 and GPT-4 has over 175 billion parameters. GPT-4 is estimated to be trained with over 1 trillion parameters.

**ChatGPT** is based on the **GPT-3.5 architecture**, and has been fine-tuned on a large corpus of conversational data, making it particularly adept at generating human-like responses to a wide range of prompts and questions.

The ChatGPT model, is trained on a large dataset of text data which comes from a variety of sources, such as books, articles, Wikipedia and scientific journals. The text data is carefully curated to ensure that it represents a diverse range of topics and styles of writing.

Currently, GPT-4 is available on ChatGPT Plus (an upgraded version of ChatGPT).
